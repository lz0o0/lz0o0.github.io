[{"content":"\rHiii！ 我是 lz0o0 ，以后在本站就自称本鲤了😎！ 听首我喜欢的歌吧~\n","permalink":"https://lz0o0.github.io/zh/posts/%E4%BD%A0%E5%A5%BD%E6%9C%8B%E5%8F%8B/","summary":"\u003c!-- {{\u003c music id=\"557578993\" type=\"song\" server=\"netease\" \u003e}}\r\n --\u003e\r\n\u003cp\u003e\u003cem\u003eHiii！\u003c/em\u003e   \u003cstrong\u003e我是 lz0o0 ，以后在本站就自称本鲤了😎！\u003c/strong\u003e  \u003cstrong\u003e听首我喜欢的歌吧~\u003c/strong\u003e\u003c/p\u003e\n\u003c!-- eva --\u003e\r\n\u003cdiv id=\"player1\" style=\"--background-url: url('https://lizhuo.space/eva-15.jpg');\"\u003e\r\n\u003cscript\u003e\r\n    const ap1 = new APlayer({\r\n        container: document.getElementById('player1'),\r\n        audio: [\r\n            {\r\n                name: 'Komm,süsser Tod (M-10 Director’s Edit. Version)',\r\n                artist: 'arianne schreiber',\r\n                url: 'https://lizhuo.space/Komm%2C%20s%C3%BCsser%20Tod%20%EF%BC%8F%E7%94%98%E3%81%8D%E6%AD%BB%E3%82%88%E3%80%81%E6%9D%A5%E3%81%9F%E3%82%8C%20(M-10%20Director%E2%80%99s%20Edit.%20Version).flac',\r\n                cover: 'https://lizhuo.space/evas.png'\r\n            }\r\n        ]\r\n    });\r\n\u003c/script\u003e\r\n\u003c/div\u003e","title":"热爱，让你成为自己~"},{"content":"\r“😁 碎碎念页面完成了, So easy！”\r--- 2025-04-18\r“AI-CFW,学习新技术总是让人兴奋！”\r--- 2025-04-17\r","permalink":"https://lz0o0.github.io/zh/posts/life/says/","summary":"😁 碎碎念页面完成了, So easy！","title":"💭 See what I Says"},{"content":"\r1. 背景 2020年至今，AI 应用井喷式爆发，各种通用 AI 大模型和一众垂类 AI 应用相继出现，并迅速席卷各个行业。AI 的迅速推广、普及，为社会的各行各业带来强大助力，也为广大用户的学习生活提供诸多便利，但于此同时， AI 应用服务从用户接入、智能体处理、外部调用到模型训练的全生命周期，普遍缺乏透明度和内容安全监管，用户隐私泄露、模型内生安全、越狱攻击、意识渗透等安全威胁的危害越发突出，AI 内容缺乏有效、可靠的技术监管机制，AI 应用安全面临新一轮挑战。\n尽管实现全周期的内容安全监管十分复杂，但仅仅在 AI 用户和 AI 应用之间，进行交互内容的监管、过滤却并非不可行，最直观的思路就是部署一个 AI 内容防火墙，下文简记为 AI-CFW。\n简言之，本项目的目标即实现一个 AI-CFW 原型系统，该系统部署于 AI 应用和 AI 使用者之间，能够对使用者的提问以及 AI 应用的回复内容进行过滤。应用于实际，AI-CFW 需要满足以下要求：\n实时发现恶意指令、越狱尝试、价值观异常的 AI 回复或违反内容合规、数据隐私要求的情况\n进行格式回复、拒绝应答或会话阻断等操作\n此项目需求来源于UCAS课程，本鲤主笔。为方便管理，在此文作记录归档。\n2. AI-CFW 设计难点与目标 AI-CFW 设计面临的主要挑战如下：\n如何将对所有大模型的访问都纳入监管？\nhttps应用普遍情况下如何获得交互内容？\n如何判定大模型输出结果是否违规？\nAI-CFW 设计面临的预期目标如下：\n流量还原与 AI 机器人的对话内容（包括但不限于文本，图片，文档等） ✓ 相关知识点：流量还原，应用识别，加密内容获取等 研究审核 AI 聊天内容中的违规内容 ✓ 相关知识点：字符串匹配过滤，内容理解，虚假信息检测等 3. 已有解法分析： 我们分析一下行业风口的巨头们都是怎么做的，他们的解法，可能对本项目有所启发。具体而言，目前已针对 AI 发布内容防火墙产品或网关的企业并不在少数，诸如火山引擎、启明星辰、Cloudflare、Kong、Gloo、 Higress、Portkey 和 OneAPI等，本鲤主要梳理了前三个厂商的产品和模式特点。（之后了解到 Portkey 、OneAPI 针对 AI 的原生特性更强，后续再作补充吧）\n①火山引擎（供给侧 AI 保障）：大模型应用防火墙 —— WAF串接模式 火山引擎是字节旗下的云服务综合平台，其推出的大模型应用防火墙（下简称LMs-WAF），主要提供算力消耗防护、提示词识别、优化内容生成和鉴权与用量配置等功能，它更加侧重于对服务侧 AI 业务的防护，力求保证 AI 应用平稳落地，提供可靠、安全、优化等服务。（关于WAF是什么，本鲤后面简单开一篇介绍）\n针对的目标群体是愿意为 AI 业务平稳运营，支付检测保障费用的 AI 企业。\nLMs-WAF 的防护结构如下图所示，包含四维防护优化：接入净化保护（可用性）、提示词注入检测、数据窃取识别、鉴权分析（外部调用、内部投毒）。\n火山 LMs-WAF 提供两种接入方式：通过CNAME接入（试用于未基于火山部署AI业务的企业）、通过火山原生CLB开启TCP监听接入。CLB即负载均衡，实际上基于CLB监听接入的方式也主要是基于CNAME的，至于原因，后面会再解释。下面是两种接入方法的部署结构拓扑：\n考虑到不同背景的小伙伴，简单介绍一下CNAME（这是域名解析中比较常见的概念，对DNS有了解或者自己鼓捣过小网站的同学应该很熟悉），其余的内容图中很直观，具体不再赘述。\n【CNAME】是域名解析中的一个记录名称，也叫别名记录，这个别名的概念是相对 A(Address) 记录而言的。域名解析的一般过程便是访问A记录，将域名映射为对应的IP地址，而CNAME记录则能够将域名解析为另一个域名，这时你发现只要将原本用户访问的域名A通过CNAME解析到域名B，那么生效后，用户在进行DNS解析时，就会直接去访问B指向的服务器地址了，访问流量走的是另外一条路径（CLB业务基本是这个模式，比如CDN中的加速资源就基本与域名绑定。这里也解释了为何上面说第二种方法实质也是基于CNAME。【火山CLB中间用监听实现内容检测的这个结构很值得思考，或许可能为旁路部署提供经验。不过这里缺乏进一步信息，难成主线，咱有空再来填坑】\n上面说了很多，个人或者小团体实际上很难用火山的模式复刻一个 AI-CFW，因为 LMs-WAF 实际更侧重AI应用的全流程业务优化防护，需要供给侧服务商的加入，个体缺乏号召力，另外这种模式的运营也十分依赖火山云服务本身够硬的能力。\n但是退一步说，LMs-WAF 比较有借鉴意义的是他们在接入层和智能体中间进行的提示词注入检测，以及参照的内容合规标准。\n【提示词注入】是一种 AI 应用攻击方式，通过分工协作的“越狱 Prompt”+“恶意诱导 Prompt”，能够绕过平台和模型原生安全机制，诱导模型生成恶意内容。现实中需要考虑服务可用性和检测严格阈值的trade-off，因而这种攻击难以根除。针对这种安全威胁，火山 LMs-WAF 采用了意图识别、防提示词注入、动态对抗与价值观校准等防护机制，通过利用 AI 能力对抗 AI 攻击，提升大模型面对提示词注入的应对能力：\n通过深度上下文引擎，可识别97%隐式攻击\n基于千万级对抗样本训练，覆盖20+提示词攻击场景，检出率达99%+\n经某大模型服务平台实测，违规内容及价值观偏移回答均下降98%\n【内容合规标准】：《生成式人工智能服务暂行管理办法》中 5 大类 31 个小类规定\n②启明星辰（用户侧数据脱敏）：大模型访问脱敏罩MADA Mask —— 网关串接模式 启明星辰是一家主攻安全服务的综合提供商，目前由中国移动实际控股，专责网信安全，覆盖网络安全、数据安全、应用业务安全等多个领域。启明星辰发布的大模型访问脱敏罩MADA Mask（Model Application Desensitization Access Mask，下简称LMs-Mask），主要关注机构对外访问开放大模型时，在充分保障共有大模型效用的前提下，如何有效避免自身敏感数据泄露的问题，其核心是为用户侧访问提供专业可靠的数据脱敏服务。\n针对的目标群体是机构或企业单位，具体服务模式和接入方式，未得到其公开声明。\nLMs-Mask 的防护结构如下图所示，其核心是保障数据上传过程中的敏感内容识别和安全脱敏：LMs-Mask串接在机构用户访问各种公域或私域大模型的路径上，提供对机构用户的数据脱敏（智能围栏、全链审计），并能够对内容进行智能阻断（NLP识别、优化调整）。\nLMs-Mask 同样提供两种部署方式，实质都是网关串接：本地网关形态部署（串接于企业网络边界出口）、SAAS化代理网关形态（串接公有云，访问特定入口。考虑目前云化的趋势，这应该是目前主流的方式）。下图是SAAS化代理网关形态的结构：\n简单补充下SaaS的概念，**SaaS（软件即服务）**是一种基于云计算的软件交付模式，通过互联网提供应用程序，用户无需购买、安装和维护软件，只需通过网络浏览器或移动应用程序访问和使用软件。通过SaaS模式的特点，可以简单猜测LMs-Mask的拓扑结构：用户通过软件/浏览器接入启明星辰提供的代理节点，节点支持请求处理和回源转发，并最终返还交付回用户。 启明星辰对 LMs 的部署模式进行了分析，简要总结例举在下方：\n全私域部署：在机构内部部署满血DeepSeek或其他全功能大模型。这样机构内部使用大模型，数据泄露的直接风险相对不高（并非完全没有）；对应机构的投入成本相对较高。 公共大模型访问开放部署：机构为内部员工提供自由访问的外部大模型。这样机构的投入最少、起步最快；数据泄露风险暴露面最大，最危险。 公共大模型访问罩部署：机构为内部员工访问外部大模型提供一个访问代理，并同时安排数据安全和其他应用安全保护。这样可以在极少的投入下，让机构全员能够获得大模型应用的收益。该部署方式和前两种部署方式并不互斥。（也就是LM-Mask的解法） 混合大模型访问体系化部署：基于AI-R-IAM身份管理、业务分割、网络分域、数据分域的复杂部署方式。这种部署模式适用于大型机构的深度应用环境。 LMs-Mask的解法比较符合本项目的需求，思路比较值得借鉴。一方面对用户侧上传的数据进行脱敏处理，防止泄露风险同时保障隐私性，另一方面，网关串接的模式对于用户几乎无感，实施相对简单。但是这种方法，数据处理和安全脱敏都较高程度地依赖代理节点，对其性能要求和可靠性要求可能较高。\n由于其未公开产品接入具体方法，本鲤对其本地串接过程和云外接访问过程中数据流的处理还有些模糊，初步猜测应该是基于证书-密钥的还原形式。\n【内容合规标准】：《数据安全法》、《个人信息保护法》\n③Cloudflare：AI gateway —— 反向代理模式 Cloudflare的大名无需多言（全球最大的CDN服务商），作为首款全球连通云，其产品线和服务囊括计算、存储、网络全栈，实力非常之雄厚（这里不得不赞，很多时候，CF很像个慈善家\u0026hellip;\u0026hellip; )。Cloudflare推出的基于其公有云Serverless的 Cloudflare AI Gateway（下简称 LMs-Gateway），是一个用于管理和扩展生成式 AI 工作负载的统一接口，用户可以通过它提高对 AI 应用程序的可见性和控制能力，它支持多方提供商，包括 OpenAI、Google Vertex AI、Azure OpenAI、HuggingFace、Amazon Bedrock 和 Anthropic（最近大火的MCP）等。\n具体而言，LMs-Gateway 的核心功能就是提供一个统一的接口，这个接口可以管理和扩展各种生成式 AI 的工作负载，包括各种访问流和 API 调用。无论模型在何处运行，只需通过将应用程序连接到 LMs-Gateway ，它就可以充当服务与具体服务提供商之间的代理，网关管理者因而可以监控用户交互的过程、进行日志记录，并利用缓存、速率限制、请求重试和模型回退等扩展功能。\n针对的目标群体相对广泛，包括个人和企业用户。\nLMs-Gateway 的结构如下，依赖其本身对多方提供商的支持能力，主要在服务和具体的服务承载工具之间充当 API 代理，整体的拓扑结构类似反向代理，就用户体验而言实际就等同于一个大模型API代理。\n借由上图中的结构，服务请求都被发送到 LMs-Gateway，网关再进行请求的转发，并从缓存读取响应回递传送给用户。这个过程中，流量进出都经过 Cloudflare ，流量的还原处理应当也是基于证书密钥。\n简言之，Cloudflare 的 AI Gateway 主要功能即一个反向代理，若用户原本直接经过 OpenAI 的 API 访问https://openai ，那么现在仅需把访问服务的 baseURL 换成https://gateway.ai.cloudflare.com/v1/${accountId}/${gatewayId}/openai 即可。\n这个方案有下面几个优点：\n只需修改 baseURL 即可接入，不改变 API 格式，接入相对简单 服务是 Serverless 的，不需要用户额外管理任何服务器 借助 Cloudflare 的全球网络可以实现一定的用户接入加速 借助 Cloudflare 的全球网络可以一定程度隐藏掉源 IP，对于访问受限的区域可有奇效 该方案对应的缺点如下：\n所有请求信息包括 API Key 都需经过 Cloudflare ，存在一定安全隐患 LMs-Gateway 扩展比较麻烦，目前提供的不支持内容检查过滤 上面两个厂商的产品，个人很难进行 demo 演示，而 Cloudflare 的 LMs-Gateway 服务又对于个人用户十分友好，因此本鲤以 LMs-Gateway 监控 MCP Server-Time 任务流过程的例子为引，简单演示下这类网关能够达到的效果，主要包含5个步骤：\n在 Cloudflare 平台创建 LMs-Gateway 实例，使用 API 作为 endpoint 连接到应用服务器，创建出口点，也即 baseURL\n在 vs code 中通过 cline 配置将大模型 API 站点都配置为从 API endpoint 访问\n在 cline 中调用一个 MCP Server：Time，简单执行一个任务，让流量流经 LMs-Gateway，下图以Time为例，简单查询了当前的北京时间\n在 LMs-Gateway 中 check 日志看看网关能捕获到什么内容。（通过请求响应的过程，其实可以对MCP请求响应的特点进行分析，这个内容本鲤目前在做，后面也要单开一篇讲）\n小结 整体而言，各家厂商发布的 AI-CFW 都呈现出以下共性：\n基本都以串接模式（网关or服务代理）接入，确保用户或局域网的访问都可纳入监管 内容合规的判断都借助 AI 赋能，参考某些内容审查标准实施 防护整体要么侧重供给侧业务保障要么关注用户侧隐私保护，并无完全独立的安全第三方（当然了，这样两头不讨好，既引入信任问题，也比较难盈利 串接尽管需要的条件强，但模式和管理都简单，优点明显，加密流量还原的难点可以一定程度绕过（真要旁路硬做加密解析，其实很头大\u0026hellip;），还原基于证书密钥应该可以基本解决；当然如果考虑旁路监听（Note：火山CLB本质还是串接）的话，火山的模式需要再深入\u0026hellip;\u0026hellip;\n通过上面的梳理，思路相对比较明确了：①串接部署：选择串接结构能够解决很多困难，包括覆盖度和流量还原问题，还原采取证书-密钥形式进行解决；管理形式最好是 Serverless，不需要对服务作过多管理。②内容合规审查：串接节点获取到还原的流量内容后，需要进一步关注流量的检查、处理和转发。重点是内容合规的标准和判断、优化方法，需要考虑多模态的复杂情况。\n4. 初步计划与设计 关于整体设计思路：\n①串接部署：串接结构选择能够解决很多困难，包括覆盖度和流量还原问题，还原思考证书-密钥形式进行解决；管理形式最好是 Serverless，不需要对服务作过多管理。 ②内容合规审查：串接节点获取到还原的流量内容后，需要进一步关注流量的检查、处理和转发，重点是内容合规的标准和判断、优化方法，需要考虑多模态的复杂情况。\n关于具体实施落地：\n①串接参考 Cloudflare 的 AI Gateway，基于证书-密钥进行流量还原。在转发和日志的基础上，需要增加检测、过滤或脱敏。（Cloudflare网关的实操上面已作示意，需要再调研如何基于证书-密钥进行流量还原（配置过程实际可以看出来了，本鲤后续跟进了Fiddler代理抓包的解密，这种形式应当可以借鉴），需要进一步调研跟进如何自建实现同类服务，以及在上面如何附加审查能力）\n②内容合规审查目前考虑加入 AI （内容理解、虚假检测支持），但只能本地微调（否则会迭代引入泄露）；另外需要基本的关键词匹配、敏感词表作基础匹配过滤的支撑；最后要考虑多模态数据的转换和统一读取问题。（基本是以文字为主，进一步要考虑doc文档、pdf文件、图片等样式数据如何读取和理解的问题\n关于分工和对口：本鲤统筹、推进\n①：全员（关键，决定思路能不能最终落地，注意这里是三个问题）\n②：AI 支撑（俊）、关键词\u0026amp;敏感词匹配（博）、多模态读取（杰）\nRefer：如有侵权，请联系删除 使用Cloudflare AI Gateway监控、控制和优化 AI 应用 - waka\u0026rsquo;s blog 大模型应用防火墙，发布！ 新赛道 | 启明星辰发布“大模型访问脱敏罩”，客户安心面对DeepSeek引爆的访问安全刚需 Cloudflare网关理解 + Cloudflare网关解读 上面埋了几个坑，简单记个账，不能吃霸王餐：\nWAF是什么 火山CLB旁路监听实现内容检测 MCP请求-响应的特点 ","permalink":"https://lz0o0.github.io/zh/posts/affair-logs/ai%E5%86%85%E5%AE%B9%E9%98%B2%E7%81%AB%E5%A2%99/","summary":"\u003c!-- more --\u003e\r\n\u003ch3 id=\"1-背景\"\u003e1. 背景\u003c/h3\u003e\n\u003cp\u003e  2020年至今，AI 应用井喷式爆发，各种通用 AI 大模型和一众垂类 AI 应用相继出现，并迅速席卷各个行业。AI 的迅速推广、普及，为社会的各行各业带来强大助力，也为广大用户的学习生活提供诸多便利，但于此同时， AI 应用服务从用户接入、智能体处理、外部调用到模型训练的全生命周期，普遍缺乏透明度和内容安全监管，用户隐私泄露、模型内生安全、越狱攻击、意识渗透等安全威胁的危害越发突出，AI 内容缺乏有效、可靠的技术监管机制，AI 应用安全面临新一轮挑战。\u003c/p\u003e","title":"AI 内容防火墙"},{"content":"\r背景 ​\t家用摄像头作为一种基础视频监控设备，近年来在中国乃至全球范围内迅速普及，成为许多家庭不可或缺的安全工具。随着技术进步和消费者对家庭安全需求的增加，市场呈现智能化、线上化和品牌竞争加剧的趋势。然而，家用摄像头在使用过程中产生并记录海里的音频和视频数据，这些数据关乎广大用户群体的各种行为活动。\n​\t用户安装家用摄像头的动机体现在两个方面：一是实时关注家中老人、孩子或宠物的动态，二是防范盗窃或入室犯罪，保护财产安全。但是随着诸多家用摄像头数据泄露事件和隐患的揭露，其伴生的数据隐私与安全风险越发受到用户关注，成为当前网络安全的热点问题。\n​\t针对背景和需求，梳理了 5 部分内容，以下给出目录，具体细节不作展开，此需求来自相关部分，本文作记录复盘。\n主要内容 家用摄像头市场情况和趋势变化 市场普及的现状与驱动因素 技术进步的推动与产品演变 渠道变迁与线上化趋势 品牌竞争与市场格局 隐私安全挑战与应对 未来市场趋势 家用摄像头数据存储模式分析 SD卡存储：家庭监控的入门之选 DVR存储：模拟时代的过渡方案 NVR存储：家用监控的主流支柱 CVR存储 云存储 数据传输与用户访问模式 数据访问传输模式 涉及传输协议及其细节 加密与压缩算法 用户可控度与可靠性 小结 安全威胁与风险 数据安全威胁 主要风险来源 小结 问题与建议 用户与厂商安全意识薄弱 缓解措施与建议 总结 ​\t家用摄像头相关的数据安全问题集中在泄露、隐私侵犯和厂商漏洞，覆盖摄像头数据存储、传输和用户访问的整个过程。目前，家用摄像头的数据存储模式包括本地、云端和混合三种，本地存储隐私性强但容量有限，云存储便利却依赖厂商安全，混合模式灵活但成本较高。传输模式与访问方式是数据安全的关键环节。本地到用户的P2P模式延迟低但跨网受限，云模式支持远程访问却易受服务器攻击，混合模式兼顾两者但操作复杂。未来，随着5G和AI普及，设备功能将扩展至健康监测等新领域，智能家居市场的增长潜力巨大。而摄像头的安全属性和厂商的安全水平将会成为用户关注的核心问题。\n​\t总体而言，家用摄像头在提升生活便利的同时，其安全风险贯穿全链条。当前，技术漏洞与管理疏忽并存，用户与厂商责任需更好协调。未来，通过技术升级、用户教育和政策约束，行业有望实现便利与安全的双赢，智能安全的摄像头将成为家庭标配，数据保护也将成为品牌竞争的关键。\n","permalink":"https://lz0o0.github.io/zh/posts/affair-logs/%E5%AE%B6%E7%94%A8%E6%91%84%E5%83%8F%E5%A4%B4%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%88%86%E6%9E%90/","summary":"本文对目前国内主流家用摄像头的情况进行了梳理，分析了市场情况和发展趋势；着眼于数据安全，侧重分析了摄像头目前数据采集存储，以及传输的模式特点，旨在揭示家用摄像头中潜藏的数据安全问题和风险","title":"家用摄像头数据安全分析"},{"content":"\r1. 问题描述 本地使用 Hugo 启动时，网站样式能够正常显示，但部署到 GitHub Pages 后，样式无法加载（如上图所示）。通过浏览器 F12 调试，控制台报错信息如下：\n1 Failed to find a valid digest in the \u0026#39;integrity\u0026#39; attribute for resource \u0026#39;https://lz0o0.github.io/assets/css/stylesheet.6da9a63d25a9608bca2f7f907a0，30e887a7dd3c3f3918e4cc113129361414bda.css\u0026#39; with computed SHA-256 integrity \u0026#39;9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=\u0026#39;. The resource has been blocked. SRI和校验失败： Subresource Integrity (SRI) 是一种安全机制，用于确保在加载资源时，它们的内容与预期的哈希值一致。如果资源的实际哈希值与 HTML 文件中 integrity 属性定义的不一致，浏览器会阻止加载资源。\n2. 原因\u0026amp;解法 根据报错信息，大致确认问题是因为 SRI 校验时hash值不匹配，CSS加载失败，从而导致网页样式无法正常显示，无法看到多彩的网页。公网上主要的解释和解决办法，主要是以下三种：\n1. Cloudflare对 JS 和 CSS，默认执行\u0026quot;Auto Minify\u0026quot;，文件压缩后和 hugo 的处理存在冲突，导致校验失效；对应禁用选项，刷新缓存即可\r2. 修改 Hugo 的文件，禁用指纹校验选项。具体而言，在config.yaml或者hugo.yaml中添加以下代码\r1 2 3 params: assets: disableFingerprinting: true 3. 修改 html 文件索引入口，禁用 SRI 校验：将文件`(themes\\PaperMod\\layouts\\partials\\head.html)`中的 **integrity** 参数索引都置空`(integrity=\u0026quot;\u0026quot;)`\r方法①本鲤不知道在哪配置，没有实操。但我认为可能是压缩的问题，因为本地加载并未出现类似问题，不一致大概来自云端的处理 方法②比较合理，然而，本鲤实际配置后没什么效果，可能是 hugo 不内置该参数了 使用方法③，本鲤成功显示了CSS样式。大部分教程只提示改(integrity=\u0026quot;{{ $stylesheet.Data.Integrity }}\u0026quot;)，但我建议你把文件中所有的 integrity 参数索引都置空，因为另外一处索引时可能也会报错，因此建议都置空\nMind！ 可按照231的顺序，如能解决最好，前端的问题比较多样，本鲤发现甚至有因为LF和CRLF问题的（比较有用的讨论或文档，附在文末 3. 小结 本文描述了Hugo+Papermod部署到github pages时，由于SRI校验失败，导致CSS文件无法正常加载，不显示网页样式内容的问题。在文档中列举了三种主要的解决方法，并且分析了可能的问题（may优化导致校验失效）。博主实际通过修改配置的html索引，禁用 SRI 校验选项，解决了该问题\n如有意指点，或碰到问题，欢迎留言讨论~\nrefer https://swopnil.com/blog/valid-digest-integrity-error-hugo-styling/ https://github.com/alanorth/hugo-theme-bootstrap4-blog/issues/53 https://stackoverflow.com/questions/65040931/hugo-failed-to-find-a-valid-digest-in-the-integrity-attribute-for-resource ","permalink":"https://lz0o0.github.io/zh/posts/error-logs/hugo%E5%8F%91%E5%B8%83%E5%90%8E%E4%BB%85%E6%96%87%E6%9C%AC%E6%98%BE%E7%A4%BAcss%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BD/","summary":"本文分析并解决了Hugo+Papermod部署到github pages时，由于SRI校验失败，导致CSS文件无法正常加载不显示网页样式内容的问题","title":"hugo发布后仅文本显示css无法加载"},{"content":"背景 内网穿透：网络连接中的一种术语，也称作NAT（毕竟NAT导致了内外网的划分）穿透，是一种用在外网（相对局域网而言，包括公网和其它局域网）计算机访问局域网内计算机节点及其服务的通信连接技术。\n内网穿透依赖的核心原理是公私网地址的映射转换，转换结果就是NAT表项的建立。按照穿透结构来说，主要包含基于服务器数据中转的穿透（穿透内网穿透解法）和点对点穿透（UDP/TCP打洞）两种，两种方法的都需要中间服务器的参与，但后者只需作为集中服务器参与协商即可（两端安装工具，服务集中协商作为服务提供），而前者的压力较大。简单而言，就是A客户端要访问B客户端，通过一台服务器进行桥接，桥接有两种方式，一种是相互转发，另一个是告诉对方的地址，自己就当一个介绍人的角色。\n内网穿透传统方式会出现服务器和客户机之间的数据传输全部经过中转服务器，传输速度将受制于中转服务器的上下行带宽，不过稳定性很好，要求云主机带宽大。相比之下，点对点穿透能解决大流量带来的困扰，可以实现服务器和客户机之间打洞直接进行数据通信。然而，这种方式需要服务器和客户机都安装穿透工具，对用户访问端不够方便，而且这种方式受复杂网络环境影响较大，不能100%实现，稳定性欠缺。\n关于穿透原理分析，详情可参考：内网穿透原理分析\n内网穿透除了可能需要云主机外，还需要穿透工具协助，几款主流的工具包括frp（开源）、ngrok（开源）、zerotier（开源/商业）、花生壳（商业）、向日葵（远程桌面）、VPN（加密穿透）等等。就各自特点而言，商业款有专业团队维护，且使用简单方便，但数据包会流经第三方，因此数据安全是一大隐患。而对于个人有动手能力的用户或者中小型企业的小规模使用可以选择开源方式。\n综合软件配置复杂度、穿透能力等因素，个人觉得目前最好的选择就是 frp 用于对流量转发不大的场景，而需要大量 udp 传输的场景可以选择zerotier。\n需求来自UCAS课程，此处作记录复盘。本文演示基于 frp 的实现，也可参考：frp内网穿透\n基于 Frp 的内网穿透实现：以内网文件共享为例 1. frp 源码获取 git：https://github.com/fatedier/frp/releases 解压：tar -zxvf frp_0.61.2_linux_amd64.tar.gz\n文件中包含 frpc、frpc.toml；frps、frps.toml；以及LICENSE文件，分别对应客户端和服务端的配置项设置，可删去相对的内容\n2. 配置 frps 服务端设置项：中转服务器 frps.toml文件配置：这里的用户和密码主要用于登录frp访问面板 1 2 3 4 5 6 7 8 9 bindPort = 7000 webServer.addr = \u0026#34;0.0.0.0\u0026#34; webServer.port = 7500 webServer.user = \u0026#34;admin\u0026#34; webServer.password = \u0026#34;admin\u0026#34; auth.method=\u0026#34;token\u0026#34; auth.token = \u0026#34;passtoken\u0026#34; 配置后启动即可，成功会显示初始化日志：./frps -c frps.toml，随后可以访问公网IP：7500网站查看访问面板，这步相当于将公网服务器的7000端口和frp转发绑定，通过用户登录限制，限制了可以访问共享服务的公网节点。需要注意的是，在服务器，必须开启以下端口（6000和6001是为内网节点共享服务配置）：\n启动服务端之后，可以进入访问面板进行登录，并简单查看，当前绑定在7000端口：\n后台挂载进程 利用systemd启动后台进程挂载，创建文件：vim /etc/systemd/system/frps.service，文件内容如下(指定了访问面板的信息和绑定端口)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description = frp server After = network.target syslog.target Wants = network.target [Service] Type=simple ExecStart = /dev-ops/frp/frps -c /dev-ops/frp/frps.toml ExecStop=/bin/kill $MAINPID Restart=always RestartSec=5 [Install] WantedBy = multi-user.target 文件创建成功后，启动即可：\n1 2 systemctl start frps systemctl status frps 3. 配置 frpc 客户端设置项：局域网节点 配置frpc.toml文件，向外网共享文件服务，向外网暴露什么服务由内网节点决定，因此上面服务端没有这部分配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #你的云服务器公网ip serverAddr = \u0026#34;x.x.x.x\u0026#34; #连接到云服务器端口,需要和frps.toml配置文件中端口一致 serverPort = 7000 auth.method = \u0026#34;token\u0026#34; auth.token = \u0026#34;passtoken\u0026#34; #开放端口连接 [[proxies]] name = \u0026#34;test-tcp\u0026#34; type = \u0026#34;tcp\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 8080 remotePort = 6100 # 服务器需要开放该端口 #共享文件访问 [[proxies]] name = \u0026#34;d_drive\u0026#34; type = \u0026#34;tcp\u0026#34; remotePort = 6001 # 服务器上用于访问的端口，需要开放该端口 [proxies.plugin] type = \u0026#34;static_file\u0026#34; localPath = \u0026#34;D:\\\\\u0026#34; # 要对外暴露的目录（这里相当于向外网暴露文件服务） stripPrefix = \u0026#34;d_drive\u0026#34; # 访问路径名，此处即http://x.x.x.x:6001/d_drive/ httpUser = \u0026#34;username\u0026#34; # 用户名 httpPassword = \u0026#34;password\u0026#34; # 密码 4. 连接客户端与服务端 确保 frpc.exe 和 frpc.toml 位于同一目录。\n切换到 frpc.exe 所在目录：cd path\\to\\frp\n执行以下命令启动客户端：.\\frpc.exe -c frpc.toml\n执行命令启动服务端： .\\frps -c frps.toml\n两端连接可以访问frp面板访问内网的文件内容；此时再次访问服务面板，共享的服务映射更新\nurl访问共享的文件服务，此时可以看到局域网节点D盘符下的文件内容，支持访问下载\nFrp 流量分析 在局域网节点，采集 frp 连接访问过程中的流量，分析其连接、数据传输过程的特点，寻找可能的风险问题\nrefer 内网穿透详解 - cyrus0w - 博客园\u0026gt; frp内网穿透零基础详细教程-CSDN博客\u0026gt; frp内网穿透最新实践教程 从零开始详细步骤_哔哩哔哩_bilibili\u0026gt; [使用frp配置内网(穿透保姆级教程])_frp内网穿透-CSDN博客\u0026gt; ","permalink":"https://lz0o0.github.io/zh/posts/nice-techs/%E5%88%A9%E7%94%A8-frp-%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/","summary":"frp 是一种反向代理工具, 被广泛用于内网穿透，能够将外网暴露内网服务，本文具体介绍了如何基于云服务器和frp源码实现简单的内网穿透，是一种很有意思和实际用处的技术","title":"利用 frp 实现内网穿透"},{"content":"\r1. 前言(๑✦ˑ_✦) 前年用 BT+Wordpress+阿里轻量化服务器 搭了个网站，当时挺上头的\u0026hellip;\u0026hellip; 后来由于服务确实卡顿，偶尔容易出问题，加上服务器每月有开销，当时又忙着准备保研和毕设，慢慢就搁置了\u0026hellip;\n前段时间，我导提到说 数字人应该有数字人的意识，最好能将自己的一生都数字化，细想起来，感觉颇显浪漫！搞起来(▼O▼ﾒ)！\n花了清明两天的时间骨架建完，还是布到公网吧，希望能定期输出新内容\u0026hellip;\n2. 摘要 Okay，个人博客的搭建过程，整体来说可以分三个部分，后两个部分，仅推荐个别博文（步骤都差不多，没必要重复堆文字，难的从来都是根据需求自定义：\n明确建站框架和基本流程：hugo+git、hexo+git、bt+wordpress 内容设计与自定义调整：结构熟悉（hugo\u0026amp;theme、自定义修改（需求\u0026amp;设计 内容发布与部署：内容与数据维护、公网发布、F\u0026amp;R 想得清楚才能做得漂亮! 灵魂三问，什么是博客？如何搭建？核心需求？ 博客是一种不错的管理方法和输出形式。你完全可以使用博客来记录、组织自己零碎的知识、经验所得，甚至于你的心理感受；维护博客的过程，也能很好锻炼你的统筹能力，更好地组织你的所想、所学、所得；此外，博客很可能是分享和展示自己的一种不错媒介\u0026hellip; 搭建博客与搭建网站的过程类似，除了一个内容加工平台或工具用于生成、编辑输出内容外，你还需要一个内容托管平台帮助你托管内容、供人访问，可以自建也可以租赁，这里 github 的优势就凸显出来了 基于 wordpress 建站比较适合商业用户，需要性能不错的服务器、域名资源，缺点网站结构相对复杂，访问容易卡顿、维护持续消耗成本；个人写作、技术博客用户，关注美观和生态，推荐 hexo ；若看重速度和轻量化，那 hugo 当仁不让 3. Demo搭建/发布+基本自定义 Demo搭建/发布：基础概念（概念和文件解读，完全不懂的，想通透点就啃啃）、一部到位版（装修以前的部分Demo搞定了，后面想想自己的需求，再去逐渐增加满足）\n基础自定义：papermod主题配置，理解基本布局、内容索引管理方法\n高阶？：没有高阶，满足你的需求就是最好的，切忌什么都要，重要的从来是内容，需要什么自己再加就是\n写在最后 再次强调一点，我认为博客本质只是一种管理方法和输出形式，特别适合像本鲤这种三天两头想要梳理东西，然后定期整点儿输出，但却因为没有好好管理，事情又一茬接一茬，从而老感觉间歇性阵痛的人\n根据我的经验，你可以先试试基于一些简单的主题，比如stack/papermod去搭demo，然后再逐渐自定义，慢慢你有感觉、熟悉规律后知道怎么改了，你可以继续上点看起来“花里胡哨”的主题，刷新刷新认识。好看并不一定好，基本代价就是结构复杂，文件多，你花在上面的时间过多，本鲤就不想在维护上浪费世界（从上面demo图，其实本站最早用blowfish搭的，结构都基本定好了，后面觉得维护稍显麻烦，终是大道至简，简单归简单但自定义空间极大\n美化网站的过程不要迷失本来的目的，想清楚自己的需求，样式都应该为内容呈现服务，不要舍本逐末\n","permalink":"https://lz0o0.github.io/zh/posts/affair-logs/blog--%E7%AE%A1%E7%90%86-+-%E8%BE%93%E5%87%BA/","summary":"如何理解博客？博客构建的逻辑和步骤是怎样的？","title":"Blog == 管理 + 输出"},{"content":"音乐, 是灵魂的语言~\n注意听, 那些是灵魂对岁月与命运的吟唱与呐喊!\n","permalink":"https://lz0o0.github.io/zh/posts/life/songs/","summary":"🤩 真的，好好好\u0026hellip;..好好听！","title":"🎧 我的歌单Songs"}]